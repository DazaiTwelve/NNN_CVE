"""
CVE NLP Mapper - Automatic CVE Discovery using Natural Language Processing
Uses semantic similarity to map vulnerabilities to CVEs
Enhanced with fallback methods and better error handling
Loads from local NVD dataset first, then tries API
"""
import requests
import json
import pickle
import os
from typing import List, Dict
from datetime import datetime
import sys


# Better import handling for Streamlit
HAS_SKLEARN = False
HAS_NLTK = False


try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    HAS_SKLEARN = True
except ImportError as e:
    pass


try:
    import nltk
    from nltk.tokenize import word_tokenize
    from nltk.corpus import stopwords
    HAS_NLTK = True
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        try:
            nltk.download('punkt', quiet=True)
            nltk.download('stopwords', quiet=True)
        except:
            HAS_NLTK = False
except ImportError:
    pass


class CVENLPMapper:
    def __init__(self, cache_dir="cve_cache"):
        """Initialize CVE NLP Mapper"""
        self.cache_dir = cache_dir
        self.cve_database = {}
        self.cve_cache_file = os.path.join(cache_dir, "cve_database.pkl")
        self.cve_index_file = os.path.join(cache_dir, "cve_index.pkl")
        os.makedirs(cache_dir, exist_ok=True)
        
        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english') if HAS_SKLEARN else None
        self.cve_vectors = None
        self.cve_list = []
        
        # Load cached CVE database
        self._load_cve_cache()
    
    def download_cve_database(self, year=None, limit=2000):
        """Load CVE data from local JSON file first, then try API"""
        print("ðŸ“¥ Loading CVE database...")
        
        # PRIORITY 1: Load from local downloaded file
        local_file = os.path.join(os.path.dirname(__file__), '../data/cve_data.json')
        
        if os.path.exists(local_file):
            try:
                print(f"ðŸ“‚ Loading local file: {local_file}")
                with open(local_file, 'r') as f:
                    data = json.load(f)
                
                # Parse NVD format
                if 'vulnerabilities' in data:
                    for item in data.get('vulnerabilities', []):
                        cve = item.get('cve', {})
                        cve_id = cve.get('id')
                        
                        if cve_id:
                            # Get description
                            descriptions = cve.get('descriptions', [])
                            desc_text = ''
                            if descriptions:
                                desc_text = descriptions[0].get('value', '')
                            
                            self.cve_database[cve_id] = {
                                'id': cve_id,
                                'description': desc_text,
                                'published': cve.get('published', 'Unknown'),
                                'updated': cve.get('lastModified', 'Unknown'),
                                'severity': 'UNKNOWN',
                                'source': 'Local NVD Dataset'
                            }
                    
                    print(f"âœ… Loaded {len(self.cve_database)} CVEs from local file")
                    self._save_cve_cache()
                    return len(self.cve_database)
            
            except Exception as e:
                print(f"âš ï¸ Local file error: {e}")
        else:
            print(f"âš ï¸ Local file not found: {local_file}")
        
        # PRIORITY 2: Download from NVD API if local file not available
        print("ðŸ”„ Attempting to download from NVD API...")
        try:
            url = "https://services.nvd.nist.gov/rest/json/cves/2.0?resultsPerPage=100&startIndex=0"
            headers = {'User-Agent': 'CVE-Scanner/1.0'}
            response = requests.get(url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                
                if 'vulnerabilities' in data:
                    for item in data.get('vulnerabilities', []):
                        cve = item.get('cve', {})
                        cve_id = cve.get('id')
                        
                        if cve_id:
                            descriptions = cve.get('descriptions', [])
                            desc_text = ''
                            if descriptions:
                                desc_text = descriptions[0].get('value', '')
                            
                            self.cve_database[cve_id] = {
                                'id': cve_id,
                                'description': desc_text,
                                'published': cve.get('published', 'Unknown'),
                                'updated': cve.get('lastModified', 'Unknown'),
                                'severity': 'UNKNOWN',
                                'source': 'NVD API'
                            }
                    
                    print(f"âœ… Downloaded {len(self.cve_database)} CVEs from NVD API")
                    self._save_cve_cache()
                    return len(self.cve_database)
        
        except Exception as e:
            print(f"âš ï¸ NVD API error: {e}")
        
        print(f"âŒ Failed to load CVE database")
        return len(self.cve_database)
    
    def _load_cve_cache(self):
        """Load cached CVE database"""
        try:
            if os.path.exists(self.cve_cache_file):
                with open(self.cve_cache_file, 'rb') as f:
                    self.cve_database = pickle.load(f)
                print(f"âœ… Loaded {len(self.cve_database)} cached CVEs")
                return True
        except Exception as e:
            pass
        
        return False
    
    def _save_cve_cache(self):
        """Save CVE database to cache"""
        try:
            with open(self.cve_cache_file, 'wb') as f:
                pickle.dump(self.cve_database, f)
            return True
        except Exception as e:
            pass
            return False
    
    def build_search_index(self):
        """Build TF-IDF index for fast searching"""
        if not HAS_SKLEARN:
            print("âš ï¸ Scikit-learn not available. Using keyword fallback.")
            return False
        
        if not self.cve_database:
            print("âš ï¸ CVE database empty. Download first.")
            return False
        
        print("ðŸ” Building search index...")
        
        try:
            self.cve_list = list(self.cve_database.items())
            descriptions = [item[1].get('description', '') for item in self.cve_list]
            descriptions = [d if d.strip() else "unknown" for d in descriptions]
            
            self.cve_vectors = self.vectorizer.fit_transform(descriptions)
            
            print(f"âœ… Index built with {len(self.cve_list)} CVEs")
            return True
        
        except Exception as e:
            print(f"âŒ Error building index: {str(e)}")
            return False
    
    def find_similar_cves(self, vulnerability_description: str, top_k=5) -> List[Dict]:
        """Find similar CVEs using TF-IDF + Cosine Similarity"""
        if not vulnerability_description or not vulnerability_description.strip():
            return []
        
        if not self.cve_database:
            return []
        
        if HAS_SKLEARN and self.cve_vectors is not None:
            return self._tfidf_similarity_search(vulnerability_description, top_k)
        elif HAS_NLTK:
            return self._keyword_matching(vulnerability_description, top_k)
        else:
            return self._simple_keyword_search(vulnerability_description, top_k)
    
    def _tfidf_similarity_search(self, vulnerability_description: str, top_k=5) -> List[Dict]:
        """TF-IDF based similarity search"""
        try:
            query_vector = self.vectorizer.transform([vulnerability_description])
            similarities = cosine_similarity(query_vector, self.cve_vectors)[0]
            
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            
            results = []
            for idx in top_indices:
                if similarities[idx] > 0.1:
                    cve_id, cve_data = self.cve_list[idx]
                    results.append({
                        'cve_id': cve_id,
                        'description': cve_data.get('description', '')[:300],
                        'similarity_score': float(similarities[idx]),
                        'severity': cve_data.get('severity', 'UNKNOWN'),
                        'published': cve_data.get('published', 'Unknown')
                    })
            
            return results
        
        except Exception as e:
            return self._keyword_matching(vulnerability_description, top_k)
    
    def _keyword_matching(self, vulnerability_description: str, top_k=5) -> List[Dict]:
        """Fallback: NLTK-based keyword matching"""
        try:
            query_tokens = set(word_tokenize(vulnerability_description.lower()))
            stop_words = set(stopwords.words('english'))
            query_tokens = query_tokens - stop_words
            
            if not query_tokens:
                return []
            
            matches = []
            
            for cve_id, cve_data in self.cve_database.items():
                desc = cve_data.get('description', '').lower()
                cve_tokens = set(word_tokenize(desc))
                
                intersection = len(query_tokens & cve_tokens)
                union = len(query_tokens | cve_tokens)
                
                if union > 0:
                    similarity = intersection / union
                    
                    if similarity > 0.05:
                        matches.append({
                            'cve_id': cve_id,
                            'description': cve_data.get('description', '')[:300],
                            'similarity_score': float(similarity),
                            'severity': cve_data.get('severity', 'UNKNOWN'),
                            'published': cve_data.get('published', 'Unknown')
                        })
            
            matches = sorted(matches, key=lambda x: x['similarity_score'], reverse=True)
            return matches[:top_k]
        
        except Exception as e:
            return self._simple_keyword_search(vulnerability_description, top_k)
    
    def _simple_keyword_search(self, vulnerability_description: str, top_k=5) -> List[Dict]:
        """Simple fallback: keyword search"""
        keywords = [k for k in vulnerability_description.lower().split() if len(k) > 3]
        
        if not keywords:
            return []
        
        matches = []
        
        for cve_id, cve_data in self.cve_database.items():
            desc = cve_data.get('description', '').lower()
            matches_count = sum(1 for k in keywords if k in desc)
            
            if matches_count > 0:
                matches.append({
                    'cve_id': cve_id,
                    'description': cve_data.get('description', '')[:300],
                    'similarity_score': float(matches_count / len(keywords)),
                    'severity': cve_data.get('severity', 'UNKNOWN'),
                    'published': cve_data.get('published', 'Unknown')
                })
        
        matches = sorted(matches, key=lambda x: x['similarity_score'], reverse=True)
        return matches[:top_k]
    
    def map_findings_to_cves(self, findings: List[Dict], confidence_threshold=0.3) -> List[Dict]:
        """Automatically map security findings to CVEs using NLP"""
        print(f"ðŸ” Mapping {len(findings)} findings to CVEs...")
        
        if not self.cve_database:
            print("âš ï¸ CVE database empty. Downloading...")
            self.download_cve_database()
            self.build_search_index()
        
        mapped_findings = []
        successful_maps = 0
        
        for finding in findings:
            query_text = f"{finding.get('title', '')} {finding.get('description', '')}"
            
            if query_text.strip():
                similar_cves = self.find_similar_cves(query_text, top_k=5)
                
                cve_ids = [
                    cve['cve_id'] for cve in similar_cves
                    if cve['similarity_score'] > confidence_threshold
                ]
                
                if cve_ids:
                    successful_maps += 1
                
                finding['cve_ids'] = cve_ids
                finding['cve_matches'] = similar_cves
            else:
                finding['cve_ids'] = []
                finding['cve_matches'] = []
            
            mapped_findings.append(finding)
        
        print(f"âœ… Mapped {successful_maps}/{len(findings)} findings to CVEs")
        return mapped_findings
    
    def get_cve_stats(self) -> Dict:
        """Get CVE database statistics"""
        return {
            'total_cves': len(self.cve_database),
            'last_updated': datetime.now().isoformat(),
            'cache_file': self.cve_cache_file,
            'indexed': self.cve_vectors is not None,
            'sklearn_available': HAS_SKLEARN,
            'nltk_available': HAS_NLTK,
            'cache_exists': os.path.exists(self.cve_cache_file)
        }
