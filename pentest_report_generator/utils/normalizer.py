"""
Data Normalizer - Enhanced with CVE Tracking
"""
from typing import List, Dict
import json

class DataNormalizer:
    def __init__(self):
        self.normalized_findings = []
        
    def normalize_findings(self, all_findings: List[Dict]) -> List[Dict]:
        """Normalize and merge findings"""
        
        # Sort by severity
        severity_order = {'Critical': 0, 'High': 1, 'Medium': 2, 'Low': 3, 'Informational': 4}
        
        sorted_findings = sorted(
            all_findings,
            key=lambda x: severity_order.get(x.get('severity', 'Informational'), 5)
        )
        
        # Merge duplicates while preserving CVEs
        merged_findings = self._merge_duplicates(sorted_findings)
        
        return merged_findings
    
    def _merge_duplicates(self, findings: List[Dict]) -> List[Dict]:
        """Merge duplicates while consolidating CVE lists"""
        merged = []
        seen = {}
        
        for finding in findings:
            key = f"{finding['host']}:{finding['port']}:{finding['title'][:50]}"
            
            if key not in seen:
                seen[key] = len(merged)
                merged.append(finding)
            else:
                # Merge CVE lists
                idx = seen[key]
                existing_cves = set(merged[idx].get('cve_ids', []))
                new_cves = set(finding.get('cve_ids', []))
                merged[idx]['cve_ids'] = list(existing_cves | new_cves)
                
                # Track multiple sources
                if 'sources' not in merged[idx]:
                    merged[idx]['sources'] = [merged[idx]['source']]
                if finding['source'] not in merged[idx]['sources']:
                    merged[idx]['sources'].append(finding['source'])
        
        return merged
    
    def export_to_json(self, findings: List[Dict], output_file: str):
        """Export findings"""
        with open(output_file, 'w') as f:
            json.dump(findings, f, indent=2)
    
    def get_statistics(self, findings: List[Dict]) -> Dict:
        """Generate statistics"""
        stats = {
            'total': len(findings),
            'by_severity': {},
            'by_host': {},
            'by_source': {},
            'cve_count': 0,
            'critical_cves': []
        }
        
        all_cves = set()
        
        for finding in findings:
            # Severity stats
            severity = finding.get('severity', 'Unknown')
            stats['by_severity'][severity] = stats['by_severity'].get(severity, 0) + 1
            
            # Host stats
            host = finding.get('host', 'Unknown')
            stats['by_host'][host] = stats['by_host'].get(host, 0) + 1
            
            # Source stats
            source = finding.get('source', 'Unknown')
            stats['by_source'][source] = stats['by_source'].get(source, 0) + 1
            
            # CVE tracking
            cves = finding.get('cve_ids', [])
            all_cves.update(cves)
            
            if finding.get('severity') in ['Critical', 'High'] and cves:
                stats['critical_cves'].extend(cves)
        
        stats['cve_count'] = len(all_cves)
        stats['critical_cves'] = list(set(stats['critical_cves']))
        
        return stats
    def map_with_nlp(self, findings: List[Dict]) -> List[Dict]:
        try:
            from pentest_report_generator.utils.cve_nlp_mapper import CVENLPMapper
        
            mapper = CVENLPMapper()
        
        # Download CVE database (first time only)
            if len(mapper.cve_database) == 0:
                mapper.download_cve_database()
        
        # Build search index
                mapper.build_search_index()
        
        # Map findings
                mapped_findings = mapper.map_findings_to_cves(findings)
        
                return mapped_findings
    
        except Exception as e:
            print(f"NLP mapping error: {str(e)}")
            return findings
